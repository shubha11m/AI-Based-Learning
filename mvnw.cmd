Absolutely â€” here is a **clean, polished, documentationâ€‘ready section** you can paste directly into your technical doc or Confluence page.  
This version includes headings, bullet points, callouts, and clear formatting.

***

# ðŸ—‚ï¸ **Claim Data Cleanup Flow â€“ Documentation**

## ðŸ“Œ **1. Overview**

The cleanup logic removes migrated memberâ€‘level claim data from Amazon Keyspaces using a **twoâ€‘stage deletion strategy**:

1.  **Fast path:** Attempt full **partition delete**
2.  **Fallback path:** If Keyspaces rejects the delete due to range limits, the system performs **adaptive rangeâ€‘window deletes** using the clustering column `servicebegindate`.

This approach ensures maximum efficiency while still handling Keyspaces limitations gracefully.

***

## ðŸ“Œ **2. Highâ€‘Level Architecture**

```text
Controller â†’ ClaimDataFixService â†’ RangeDeleteNTClaimService â†’ ClaimsDeleteRepository
```

***

## ðŸ“Œ **3. Detailed Flow**

### **3.1 Controller Layer**

#### `ClaimDataFixController.cleanupByMemberKey(payerKey, files)`

*   Starts an **asynchronous cleanup job** using `TaskExecutor`.
*   Delegates to:
    ```java
    ClaimDataFixService.migratedClaimsDelete(payerKey, files)
    ```

***

### **3.2 Service Layer**

#### `ClaimDataFixService.migratedClaimsDelete(payerKey, files)`

For each S3 file:

1.  Reads the file through  
    `S3Repository.processAndMoveFileFromRawBucket(file, processor, "deleted-members")`
2.  The processor converts each row â†’ `PayerMemberDTO`
3.  Extracts `memberKeys`
4.  Calls:
    ```java
    RangeDeleteNTClaimService.deleteMembers(payerKey, memberKeys)
    ```

***

## ðŸ“Œ **4. Member Cleanup Logic**

### `RangeDeleteNTClaimService.deleteMembers(payerKey, memberKeys)`

*   Processes each member **in parallel**
*   Each member key is handled via:
    ```java
    deleteWithFallback(payerKey, memberKey)
    ```

***

## ðŸ“Œ **5. Partition Delete + Fallback Strategy**

### **5.1 Fast Path**

#### `deleteWithFallback(payerKey, memberKey)`

1.  Attempt a **partition-level delete**:
    ```java
    claimsDeleteRepo.deleteClaimsByPayerAndMember(payerKey, memberKey)
    ```
2.  **If successful** â†’ cleanup complete.
3.  **If fails with â€œrange delete requests are limitedâ€** â†’ fallback begins.

***

## ðŸ“Œ **6. Fallback Delete: Adaptive Range Cleanup**

### **6.1 Yearly Window Loop**

For memberKey:

*   Iterate from **1970â€‘01â€‘01 to today + 1 day**, one year at a time.
*   For each yearly window:
    ```java
    deleteRangeAdaptive(payerKey, memberKey, from, to, 12)
    ```

***

### **6.2 Adaptive Delete Execution**

#### `deleteRangeAdaptive(payerKey, memberKey, from, to, monthsPerChunk)`

Runs deletes like:

```sql
DELETE ...
WHERE payerKey=?
  AND memberKey=?
  AND servicebegindate >= ?
  AND servicebegindate < ?
```

If Keyspaces still rejects the delete due to range limits, it automatically reduces the window size:

    12 months â†’ 6 months â†’ 3 months â†’ 1 month

Retries continue until the entire date window is deleted successfully.

***

## ðŸ“Œ **7. Duplicate Cleanup**

After the entire date range is processed:

```java
claimsDeleteRepo.deleteDupByPayerAndMember(payerKey, memberKey)
```

Ensures any leftover duplicate rows are removed.

***

## ðŸ“Œ **8. Visual Flow (Per memberKey)**

```text
deleteMembers()
 â””â”€â”€ deleteWithFallback()
       â”œâ”€â”€ Try: deleteClaimsByPayerAndMember()
       â”‚       â”œâ”€â”€ SUCCESS â†’ DONE
       â”‚       â””â”€â”€ FAIL (range limit) â†’ fallback
       â””â”€â”€ For each year:
             â””â”€â”€ deleteRangeAdaptive(12 months)
                     â””â”€â”€ If limit â†’ retry 6 â†’ 3 â†’ 1 month
       â””â”€â”€ deleteDupByPayerAndMember()
```

***

If you want, I can also generate:

âœ¨ **Mermaid sequence diagram**  
âœ¨ **Process flowchart (PNG or SVG)**  
âœ¨ **Confluence-compatible formatting**

Just tell me!
